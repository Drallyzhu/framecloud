<?xml version="1.0" encoding="UTF-8"?>
<configuration>
	<property name="LOG_HOME" value="/logs/test/frameclouduser" />
    <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
        <encoder charset="UTF-8">
            <!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符-->
            <pattern>%boldBlue(%d{yyyy-MM-dd HH:mm:ss}) [%highlight(%-5level)] %magenta(%logger{50}) - %msg%n</pattern>
        </encoder>
    </appender>
    <!-- 每天生成日志文件,文件大小超过50则新生成一个文件，同时将旧文件按${LOG_HOME}/logs/aa.%d{yyyy-MM-dd}.%i.log.zip格式压缩，文件保存30天 -->
    <appender name="infoFile" class="ch.qos.logback.core.rolling.RollingFileAppender"> 
        <file>${LOG_HOME}/info.log</file> <!-- 日志名称 -->
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy"> 
            <fileNamePattern>${LOG_HOME}/%d{yyyy-MM-dd}/info.%d{yyyy-MM-dd}.%i.zip</fileNamePattern> 
            <maxFileSize>50MB</maxFileSize>  <!-- 日志文件过大会使的编辑器打开非常慢，因此设置日志最大50MB -->
            <maxHistory>30</maxHistory>  <!-- 保存30天 -->
            <totalSizeCap>100GB</totalSizeCap>  <!-- 总日志大小 -->
        </rollingPolicy> 
        <!-- encoder负责两件事，一是把日志信息转换成字节数组，二是把字节数组写入到输出流。 -->
        <encoder> 
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%-5level] %logger{50} - %msg%n</pattern> 
        </encoder> 
        <!-- 过滤器，可以过滤掉不符合条件的日志，INFO及以上的日志被处理，其它的拒绝 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter"> 
            <level>INFO</level> 
            <onMatch>ACCEPT</onMatch> 
            <onMismatch>DENY</onMismatch> 
        </filter> 
    </appender>
 
 
    <appender name="warnFile" class="ch.qos.logback.core.rolling.RollingFileAppender"> 
        <file>${LOG_HOME}/warn.log</file> 
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy"> 
            <fileNamePattern>${LOG_HOME}/%d{yyyy-MM-dd}/warn.%d{yyyy-MM-dd}.%i.zip</fileNamePattern> 
            <maxFileSize>50MB</maxFileSize> 
            <maxHistory>30</maxHistory> 
            <totalSizeCap>10GB</totalSizeCap> 
        </rollingPolicy> 
        <encoder> 
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%-5level] %logger{50} - %msg%n</pattern> 
        </encoder> 
        <filter class="ch.qos.logback.classic.filter.LevelFilter"> 
            <level>WARN</level> 
            <onMatch>ACCEPT</onMatch> 
            <onMismatch>DENY</onMismatch> 
        </filter> 
    </appender>
     
     
    <appender name="errorFile" class="ch.qos.logback.core.rolling.RollingFileAppender"> 
        <file>${LOG_HOME}/error.log</file> 
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy"> 
            <fileNamePattern>${LOG_HOME}/%d{yyyy-MM-dd}/error.%d{yyyy-MM-dd}.%i.zip</fileNamePattern> 
            <maxFileSize>50MB</maxFileSize> 
            <maxHistory>30</maxHistory> 
            <totalSizeCap>10GB</totalSizeCap> 
        </rollingPolicy> 
        <encoder> 
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%-5level] %logger{50} - %msg%n</pattern> 
        </encoder> 
        <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
    		<level>ERROR</level>
    	</filter>
    </appender>
    
    <!-- myibatis log configure -->
    <logger name="com.apache.ibatis" level="DEBUG"/>
    <logger name="java.sql.Connection" level="DEBUG"/>
    <logger name="java.sql.Statement" level="DEBUG"/>
    <logger name="java.sql.PreparedStatement" level="DEBUG"/>

	<logger name="org.springframework.scheduling">
	    <level value="info" />
	</logger>
	<logger name="log4j.logger.org.springframework">
	    <level value="error" />
	</logger>
	<logger name="org.springframework.session.web.http.SessionRepositoryFilter.SESSION_LOGGER" level="OFF" />
	<logger name="org.springframework.amqp.rabbit.listener.BlockingQueueConsumer" level="OFF" />
    <!-- 日志输出级别 -->
    <root level="INFO">
        <appender-ref ref="STDOUT" />
        <appender-ref ref="infoFile" />
        <appender-ref ref="warnFile" />
        <appender-ref ref="errorFile" />
    </root>
</configuration>