<?xml version="1.0" encoding="UTF-8"?>
<configuration>
	<property name="LOG_HOME" value="logs" />
	<appender name="STDOUT"
		class="ch.qos.logback.core.ConsoleAppender">
		<encoder charset="UTF-8">
			<!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符 -->
			<pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%-5level] [%thread] %logger{50} - %msg%n</pattern>
		</encoder>
	</appender>
	<!-- 每天生成日志文件,文件大小超过50则新生成一个文件，同时将旧文件按${LOG_HOME}/logs/aa.%d{yyyy-MM-dd}.%i.log.zip格式压缩，文件保存30天 -->
	<!-- 时间滚动输出 level为 INFO 日志 -->
	<appender name="infoFile"
		class="ch.qos.logback.core.rolling.RollingFileAppender">
		<!-- 正在记录的日志文件的路径及文件名 -->
		<file>${LOG_HOME}/info.log</file>
		<!--日志文件输出格式 -->
		<encoder>
			<pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%-5level] [%thread] %logger{50} - %msg%n</pattern>
			<charset>UTF-8</charset>
		</encoder>

		<rollingPolicy
			class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
			<!-- rollover daily -->
			<fileNamePattern>${LOG_HOME}/%d{yyyy-MM-dd}/info/info-%d{yyyy-MM-dd}.%i.log
			</fileNamePattern>
			<!-- each file should be at most 100MB, keep 60 days worth of history, 
				but at most 20GB -->
			<maxFileSize>100MB</maxFileSize>
			<maxHistory>60</maxHistory>
			<totalSizeCap>20GB</totalSizeCap>
		</rollingPolicy>

		<!-- 此日志文件只记录info级别的 -->
		<filter class="ch.qos.logback.classic.filter.LevelFilter">
			<level>info</level>
			<onMatch>ACCEPT</onMatch>
			<onMismatch>DENY</onMismatch>
		</filter>
	</appender>


	<appender name="warnFile"
		class="ch.qos.logback.core.rolling.RollingFileAppender">
		<file>${LOG_HOME}/warn.log</file>
		<rollingPolicy
			class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
			<!-- rollover daily -->
			<fileNamePattern>${LOG_HOME}/%d{yyyy-MM-dd}/warn/warn-%d{yyyy-MM-dd}.%i.log
			</fileNamePattern>
			<!-- each file should be at most 100MB, keep 60 days worth of history, 
				but at most 20GB -->
			<maxFileSize>100MB</maxFileSize>
			<maxHistory>60</maxHistory>
			<totalSizeCap>20GB</totalSizeCap>
		</rollingPolicy>
		<encoder>
			<pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%-5level] [%thread] %logger{50} - %msg%n
			</pattern>
		</encoder>
		<filter class="ch.qos.logback.classic.filter.LevelFilter">
			<level>WARN</level>
			<onMatch>ACCEPT</onMatch>
			<onMismatch>DENY</onMismatch>
		</filter>
	</appender>


	<appender name="errorFile"
		class="ch.qos.logback.core.rolling.RollingFileAppender">
		<file>${LOG_HOME}/error.log</file>
		<rollingPolicy
			class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
			<!-- rollover daily -->
			<fileNamePattern>${LOG_HOME}/%d{yyyy-MM-dd}/error/error-%d{yyyy-MM-dd}.%i.log
			</fileNamePattern>
			<!-- each file should be at most 100MB, keep 60 days worth of history, 
				but at most 20GB -->
			<maxFileSize>100MB</maxFileSize>
			<maxHistory>60</maxHistory>
			<totalSizeCap>20GB</totalSizeCap>
		</rollingPolicy>
		<encoder>
			<pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%-5level] [%thread] %logger{50} - %msg%n
			</pattern>
		</encoder>
		<filter class="ch.qos.logback.classic.filter.ThresholdFilter">
			<level>ERROR</level>
		</filter>
	</appender>

	<!-- myibatis log configure -->
	<logger name="com.apache.ibatis" level="DEBUG" />
	<logger name="java.sql.Connection" level="DEBUG" />
	<logger name="java.sql.Statement" level="DEBUG" />
	<logger name="java.sql.PreparedStatement" level="DEBUG" />

	<logger name="org.springframework.scheduling">
		<level value="info" />
	</logger>
	<logger name="log4j.logger.org.springframework">
		<level value="error" />
	</logger>
	<logger
		name="org.springframework.session.web.http.SessionRepositoryFilter.SESSION_LOGGER"
		level="OFF" />
	<!-- 日志输出级别 -->
	<root level="DEBUG">
		<appender-ref ref="STDOUT" />
		<appender-ref ref="infoFile" />
		<appender-ref ref="warnFile" />
		<appender-ref ref="errorFile" />
	</root>
</configuration>